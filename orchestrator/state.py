from typing import TypedDict, List, Dict, Optional, Any, Annotated
from langgraph.graph.message import add_messages
import operator

class Task(TypedDict):
    """
    Represents a single unit of work in the system.
    """
    id: str
    description: str
    assigned_role: str  # 'ui_agent', 'db_agent', 'logic_agent', 'deploy_agent'
    status: str         # 'pending', 'running', 'completed', 'failed'
    dependencies: List[str] # List of Task IDs this task depends on
    retry_count: int
    feedback: Optional[str] # Error details if failed, or previous attempt feedback

def merge_tasks(current: List[Task], updates: List[Task]) -> List[Task]:
    current = current or []
    updates = updates or []
    
    # Map current tasks by ID
    task_map = {t['id']: t for t in current}
    
    # Apply updates
    for t in updates:
        task_map[t['id']] = t
        
    # Reconstruct list maintaining order
    result_list = []
    
    # 1. Add known tasks in original order (updated if needed)
    for t in current:
        result_list.append(task_map[t['id']])
        
    # 2. Add truly new tasks
    existing_ids = set(t['id'] for t in current)
    for t in updates:
        if t['id'] not in existing_ids:
            result_list.append(t)
            
    return result_list

def reduce_max(left: Optional[int], right: Optional[int]) -> int:
    left = left if left is not None else 0
    right = right if right is not None else 0
    return max(left, right)

class TokenUsage(TypedDict):
    input_tokens: int
    output_tokens: int
    total_tokens: int

def reduce_usage(left: Optional[TokenUsage], right: Optional[TokenUsage]) -> TokenUsage:
    left = left or {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}
    right = right or {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}
    
    return {
        "input_tokens": left.get("input_tokens", 0) + right.get("input_tokens", 0),
        "output_tokens": left.get("output_tokens", 0) + right.get("output_tokens", 0),
        "total_tokens": left.get("total_tokens", 0) + right.get("total_tokens", 0)
    }


def merge_deployment_urls(current: Optional[Dict[str, str]], updates: Optional[Dict[str, str]]) -> Dict[str, str]:
    """
    Merge deployment URLs from different deploy tasks.
    Updates override current values for the same keys.
    """
    current = current or {}
    updates = updates or {}
    return {**current, **updates}


class SharedState(TypedDict):
    """
    Global state shared across all nodes in the graph.
    """
    # Chat history with the user and internal monologues
    messages: Annotated[List[Any], add_messages]
    
    # The master plan generated by the Supervisor
    # Uses a custom reducer to allow parallel updates from different workers
    tasks_queue: Annotated[List[Task], merge_tasks]
    
    # Current snapshot of the file system (to avoid re-reading unchanged files)
    # Mapping: "path/to/file" -> "file_hash" or concise summary
    files_snapshot: Dict[str, str]
    
    # Accumulated error logs for analysis
    error_logs: List[Dict[str, Any]]
    
    # Global retry counters to prevent infinite loops (Graph recursion limit)
    recursion_depth: Annotated[int, reduce_max]
    
    # Token usage tracking
    token_usage: Annotated[TokenUsage, reduce_usage]
    
    # Deployment URLs collected from deploy tasks
    # Keys: 'vercel_preview', 'vercel_production', 'supabase_project', 'supabase_function'
    deployment_urls: Annotated[Dict[str, str], merge_deployment_urls]
    
    # spec-feature related fields
    spec_path: str  # Path to spec directory (default: 'spec/')
    feature_name: Optional[str]  # Current feature name extracted from #feature# format
    spec_review_status: str  # 'pending', 'approved', 'needs_revision'
    spec_questions: List[str]  # Questions from reviewer
    final_validation_report: Optional[Dict[str, Any]]  # Final validation report
